{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RandNet.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tjgNn3EUWu3E","executionInfo":{"status":"ok","timestamp":1626590625365,"user_tz":-330,"elapsed":7871,"user":{"displayName":"NEIL PARESH MEHTA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsKd7M0H1Ghtta64n6eNaGRg03HOsuCRSk0KNj1A=s64","userId":"02534006225616056494"}},"outputId":"8fb9bc6f-73c7-404b-c620-bdb2afd40556"},"source":["!pip install sacred"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Collecting sacred\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/8c/b99f668e8ca9747dcd374bb46cac808e58f3cb8e446df1b3e667f6be9778/sacred-0.8.2-py2.py3-none-any.whl (106kB)\n","\u001b[K     |████████████████████████████████| 112kB 5.0MB/s \n","\u001b[?25hRequirement already satisfied: wrapt<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from sacred) (1.12.1)\n","Collecting py-cpuinfo>=4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/ba/77120e44cbe9719152415b97d5bfb29f4053ee987d6cb63f55ce7d50fadc/py-cpuinfo-8.0.0.tar.gz (99kB)\n","\u001b[K     |████████████████████████████████| 102kB 4.9MB/s \n","\u001b[?25hRequirement already satisfied: docopt<1.0,>=0.3 in /usr/local/lib/python3.7/dist-packages (from sacred) (0.6.2)\n","Collecting GitPython\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/91/b38c4fabb6e5092ab23492ded4f318ab7299b19263272b703478038c0fbc/GitPython-3.1.18-py3-none-any.whl (170kB)\n","\u001b[K     |████████████████████████████████| 174kB 9.0MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=18.0 in /usr/local/lib/python3.7/dist-packages (from sacred) (21.0)\n","Collecting munch<3.0,>=2.0.2\n","  Downloading https://files.pythonhosted.org/packages/cc/ab/85d8da5c9a45e072301beb37ad7f833cd344e04c817d97e0cc75681d248f/munch-2.5.0-py2.py3-none-any.whl\n","Collecting jsonpickle<2.0,>=1.2\n","  Downloading https://files.pythonhosted.org/packages/e9/ec/35910cf6ab87f8a013036f01f732f871a23b6058123a7bd0c7b08fbbc937/jsonpickle-1.5.2-py2.py3-none-any.whl\n","Collecting colorama>=0.4\n","  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n","Collecting gitdb<5,>=4.0.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n","\u001b[K     |████████████████████████████████| 71kB 6.7MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.0; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from GitPython->sacred) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=18.0->sacred) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from munch<3.0,>=2.0.2->sacred) (1.15.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from jsonpickle<2.0,>=1.2->sacred) (4.6.1)\n","Collecting smmap<5,>=3.0.1\n","  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->jsonpickle<2.0,>=1.2->sacred) (3.5.0)\n","Building wheels for collected packages: py-cpuinfo\n","  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-cp37-none-any.whl size=22258 sha256=8011330068e02960c343ee5e039f04a65f74f688947f5e5f26690bccdbd84ae8\n","  Stored in directory: /root/.cache/pip/wheels/2e/15/f5/aa2a056d223903b52cf4870134e3a01df0c723816835dd08db\n","Successfully built py-cpuinfo\n","Installing collected packages: py-cpuinfo, smmap, gitdb, GitPython, munch, jsonpickle, colorama, sacred\n","Successfully installed GitPython-3.1.18 colorama-0.4.4 gitdb-4.0.7 jsonpickle-1.5.2 munch-2.5.0 py-cpuinfo-8.0.0 sacred-0.8.2 smmap-4.0.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IhLXuzNZRQ1r"},"source":["Data loader"]},{"cell_type":"code","metadata":{"id":"fcywMnnuRPq4","executionInfo":{"status":"ok","timestamp":1626590633205,"user_tz":-330,"elapsed":388,"user":{"displayName":"NEIL PARESH MEHTA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsKd7M0H1Ghtta64n6eNaGRg03HOsuCRSk0KNj1A=s64","userId":"02534006225616056494"}}},"source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","import torchvision\n","import numpy as np\n","from tqdm import tqdm\n","\n","import sys\n","\n","sys.path.append(\"src/\")\n","\n","# import utils\n","\n","\n","def get_MNIST_loaders(batch_size, shuffle=False, train_batch=None, test_batch=None):\n","    if train_batch == None:\n","        train_loader = get_MNIST_loader(batch_size, trainable=True, shuffle=shuffle)\n","    else:\n","        train_loader = get_MNIST_loader(train_batch, trainable=True, shuffle=shuffle)\n","\n","    if test_batch == None:\n","        test_loader = get_MNIST_loader(batch_size, trainable=False, shuffle=shuffle)\n","    else:\n","        test_loader = get_MNIST_loader(test_batch, trainable=False, shuffle=shuffle)\n","    return train_loader, test_loader\n","\n","\n","def get_MNIST_loader(batch_size, trainable=True, shuffle=False):\n","    loader = torch.utils.data.DataLoader(\n","        torchvision.datasets.MNIST(\n","            \"../data\",\n","            train=trainable,\n","            download=True,\n","            transform=torchvision.transforms.Compose(\n","                [torchvision.transforms.ToTensor()]\n","            ),\n","        ),\n","        batch_size=batch_size,\n","        shuffle=shuffle,\n","    )\n","    return loader\n","\n","\n","class SparseVectorDataset(Dataset):\n","    def __init__(self, n, dim, ones, transform=None, seed=None):\n","        self.samples = generate_sparse_samples(n, dim, ones, seed)\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return self.samples.shape[1]\n","\n","    def __getitem__(self, idx):\n","        sample = self.samples[:, idx].reshape(-1, 1, 1)\n","        if self.transform:\n","            sample = self.transform(sample).float()\n","\n","        return sample\n","\n","\n","class SparseCompImageDataset(Dataset):\n","    def __init__(self, n, dim, ones, real_H, phi, transform=None):\n","        self.sparse_vectors = generate_sparse_samples(n, dim, ones)\n","        print(self.sparse_vectors.shape)\n","        self.comp_img = np.dot(real_H, self.sparse_vectors)\n","        self.img = np.dot(phi, self.comp_img)\n","        self.samples = np.dot(phi.T, self.img)\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return self.samples.shape[1]\n","\n","    def __getitem__(self, idx):\n","        sample = self.samples[:, idx].reshape(-1, 1, 1)\n","        img = self.img[:, idx].reshape(-1, 1, 1)\n","        if self.transform:\n","            sample = self.transform(sample).float()\n","            img = self.transform(img).float()\n","        return sample, img\n","\n","\n","class EncodingDataset(Dataset):\n","    def __init__(self, data_loader, net, device=None, transform=None, seed=None):\n","        self.samples = []\n","        self.c = []\n","        print(\"create encoding dataset.\")\n","        for idx, (img, c) in tqdm(enumerate(data_loader)):\n","            img = img.to(device)\n","            img = img.view(-1, net.D_org, 1)\n","\n","            if len(net.phi.size()) == 3:\n","                i = idx % net.phi.size(0)\n","\n","            _, enc, _ = net((i, img))\n","\n","            self.samples.append(enc)\n","            self.c.append(c)\n","\n","        self.samples = torch.cat(self.samples)\n","        self.c = torch.cat(self.c)\n","        self.D_enc = net.D_enc\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return self.samples.shape[0]\n","\n","    def __getitem__(self, idx):\n","        sample = self.samples[idx].reshape(-1, self.D_enc, 1)\n","\n","        if self.transform:\n","            sample = self.transform(sample).float()\n","\n","        return sample, self.c[idx]\n","\n","\n","def generate_sparse_samples(n, dim, ones, seed=None, unif=True):\n","    samples = np.zeros((n, dim))\n","    np.random.seed(seed)\n","    for i in range(n):\n","        ind = np.random.choice(dim, ones, replace=False)\n","        if unif:\n","            # draws amplitude from [-5,-4] U [4,5] uniformly\n","            samples[i][ind] = np.random.uniform(4, 5, ones) * (\n","                (np.random.uniform(0, 1, ones) > .5) * 2 - 1\n","            )\n","        else:\n","            # amplitude is 1 or -1 .5 prob of each\n","            samples[i][ind] = np.array([1] * ones) * (\n","                (np.random.uniform(0, 1, ones) > .5) * 2 - 1\n","            )\n","    return samples.T\n","\n","\n","def generate_sparse_phi(sparsity, num_phi, D_enc, D_img):\n","    phis = [\n","        torch.tensor(generate_sparse_samples(D_img, D_enc, sparsity, unif=False))\n","        .float()\n","        .t()\n","        for _ in range(num_phi)\n","    ]\n","    return torch.stack(phis)\n","\n","\n","def generate_simulated_data(hyp):\n","    seed = hyp[\"seed\"]\n","    D_enc = hyp[\"D_enc\"]\n","    D_org = hyp[\"D_org\"]\n","    D_comp = hyp[\"D_comp\"]\n","    sparsity = hyp[\"sparsity\"]\n","    randomness = hyp[\"randomness\"]\n","    num_phis = hyp[\"num_phis\"]\n","    num_nonzero = hyp[\"num_nonzero\"]\n","    num_samples = hyp[\"num_samples\"]\n","    batch_size = hyp[\"batch_size\"]\n","\n","    torch.manual_seed(seed)\n","    real_H = utils.normalize(torch.randn(D_org, D_enc)).float()\n","    noise = utils.normalize(torch.randn(D_org, D_enc)) * randomness\n","    H_init = utils.normalize(real_H * (1 - randomness) + noise)\n","    phis = generate_sparse_phi(sparsity, num_phis, D_org, D_comp)\n","\n","    dataset = SparseVectorDataset(\n","        num_samples,\n","        D_enc,\n","        num_nonzero,\n","        transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor()]),\n","        seed=seed,\n","    )\n","    data_loader = DataLoader(dataset, batch_size=batch_size)\n","\n","    return real_H, H_init, phis, data_loader\n","\n","\n","def get_encoding_loaders(train_loader, test_loader, net, hyp):\n","    train_dataset = EncodingDataset(train_loader, net, hyp[\"device\"])\n","    test_dataset = EncodingDataset(test_loader, net, hyp[\"device\"])\n","    enc_tr_loader = DataLoader(train_dataset, batch_size=hyp[\"batch_size\"])\n","    enc_te_loader = DataLoader(test_dataset, batch_size=hyp[\"batch_size\"])\n","    return enc_tr_loader, enc_te_loader"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5bgreytQSoJ-"},"source":["## CrsAE Model"]},{"cell_type":"code","metadata":{"id":"3BOKdub7St2v","executionInfo":{"status":"ok","timestamp":1626590635917,"user_tz":-330,"elapsed":875,"user":{"displayName":"NEIL PARESH MEHTA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsKd7M0H1Ghtta64n6eNaGRg03HOsuCRSk0KNj1A=s64","userId":"02534006225616056494"}}},"source":["import torch\n","import torch.nn.functional as F\n","import numpy as np\n","\n","# import utils\n","\n","\n","class CRsAEDense(torch.nn.Module):\n","    def __init__(self, hyp, H=None):\n","        super(CRsAEDense, self).__init__()\n","\n","        self.T = hyp[\"num_iters\"]\n","        self.L = hyp[\"L\"]\n","        self.lam = hyp[\"lam\"]\n","        self.D_in = hyp[\"D_in\"]\n","        self.D_enc = hyp[\"D_enc\"]\n","        self.device = hyp[\"device\"]\n","\n","        if H is None:\n","            self.H = torch.nn.Parameter(\n","                F.normalize(torch.randn(self.D_in, self.D_enc), dim=0)\n","            )\n","        else:\n","            self.H = torch.nn.Parameter(H)\n","\n","        self.H = self.H.to(self.device)\n","\n","        self.relu = torch.nn.ReLU()\n","\n","    def normalize(self):\n","        self.H.data = F.normalize(self.H.data, dim=0)\n","\n","    def forward(self, x):\n","        num_batches = x.shape[0]\n","\n","        x_old = torch.zeros(num_batches, self.D_enc, 1, device=self.device)\n","        yk = torch.zeros(num_batches, self.D_enc, 1, device=self.device)\n","        x_new = torch.zeros(num_batches, self.D_enc, 1, device=self.device)\n","        t_old = torch.tensor(1, device=self.device).float()\n","        for t in range(self.T):\n","            H_wt = x - torch.matmul(self.H, yk.reshape(-1, self.D_enc, 1))\n","            x_new = yk + torch.matmul(torch.t(self.H), H_wt) / self.L\n","            x_new = self.relu(torch.abs(x_new) - self.lam / self.L) * torch.sign(x_new)\n","\n","            t_new = (1 + torch.sqrt(1 + 4 * t_old * t_old)) / 2\n","            yk = x_new + (t_old - 1) / t_new * (x_new - x_old)\n","\n","            x_old = x_new\n","            t_old = t_new\n","\n","        z = torch.matmul(self.H, x_new)\n","\n","        return z, x_new\n","\n","\n","class CRsAERandProj(torch.nn.Module):\n","    def __init__(self, hyp, H=None, phi=None):\n","        super(CRsAERandProj, self).__init__()\n","\n","        self.T = hyp[\"num_iters\"]\n","        self.L = hyp[\"L\"]\n","        self.lam = hyp[\"lam\"]\n","        self.D_in = hyp[\"D_in\"]\n","        self.D_org = hyp[\"D_org\"]\n","        self.D_enc = hyp[\"D_enc\"]\n","        self.device = hyp[\"device\"]\n","        self.eval_mode = False\n","\n","        if H is None:\n","            self.H = F.normalize(torch.randn(self.D_org, self.D_enc), dim=0)\n","        else:\n","            self.H = H\n","\n","        if phi is None:\n","            self.phi = F.normalize(torch.randn(1, self.D_in, self.D_org), dim=0)\n","        else:\n","            self.phi = phi\n","\n","        self.H = torch.nn.Parameter(self.H)\n","        self.phi = torch.nn.Parameter(self.phi)\n","        self.phi.requires_grad = False\n","\n","        self.H = self.H.to(self.device)\n","        self.phi = self.phi.to(self.device)\n","\n","        self.relu = torch.nn.ReLU()\n","\n","    def normalize(self):\n","        self.H.data = F.normalize(self.H.data, dim=0)\n","\n","    def forward(self, x):\n","\n","        # if testing use the H with the lowest err_H\n","        if self.eval_mode:\n","            H = self.bestH\n","        else:\n","            H = self.H\n","\n","        # for multiple phi use ith phi for image x\n","        if isinstance(x, tuple):\n","            i, x = x\n","            phiH = torch.matmul(self.phi[i], H)\n","        else:\n","            phiH = torch.matmul(self.phi, H)\n","\n","        num_batches = x.shape[0]\n","\n","        x_old = torch.zeros(num_batches, self.D_enc, 1, device=self.device)\n","        yk = torch.zeros(num_batches, self.D_enc, 1, device=self.device)\n","        x_new = torch.zeros(num_batches, self.D_enc, 1, device=self.device)\n","        t_old = torch.tensor(1, device=self.device).float()\n","\n","        phiH = phiH.to(self.device)\n","\n","        for t in range(self.T):\n","            H_wt = x - torch.matmul(phiH, yk.reshape(-1, self.D_enc, 1))\n","            x_new = yk + torch.matmul(torch.t(phiH), H_wt) / self.L\n","            x_new = self.relu(torch.abs(x_new) - self.lam / self.L) * torch.sign(x_new)\n","\n","            t_new = (1 + torch.sqrt(1 + 4 * t_old * t_old)) / 2\n","            yk = x_new + (t_old - 1) / t_new * (x_new - x_old)\n","\n","            x_old = x_new\n","            t_old = t_new\n","\n","        z = torch.matmul(phiH, x_new)\n","\n","        return z, x_new\n","\n","\n","class CRsAERandProjClassifier(torch.nn.Module):\n","    def __init__(self, hyp, H=None, phi=None):\n","        super(CRsAERandProjClassifier, self).__init__()\n","\n","        self.T = hyp[\"num_iters\"]\n","        self.L = hyp[\"L\"]\n","        self.lam = hyp[\"lam\"]\n","        self.D_in = hyp[\"D_in\"]\n","        self.D_org = hyp[\"D_org\"]\n","        self.D_enc = hyp[\"D_enc\"]\n","        self.device = hyp[\"device\"]\n","        self.eval_mode = False\n","\n","        if H is None:\n","            self.H = F.normalize(torch.randn(self.D_org, self.D_enc), dim=0)\n","        else:\n","            self.H = H\n","\n","        if phi is None:\n","            self.phi = F.normalize(torch.randn(1, self.D_in, self.D_org), dim=0)\n","        else:\n","            self.phi = phi\n","\n","        self.H = torch.nn.Parameter(self.H)\n","        self.phi = torch.nn.Parameter(self.phi)\n","        self.phi.requires_grad = False\n","\n","        self.H = self.H.to(self.device)\n","        self.phi = self.phi.to(self.device)\n","\n","        self.relu = torch.nn.ReLU()\n","        self.classifier = torch.nn.Linear(self.D_enc, 10)\n","        self.classifier = self.classifier.to(self.device)\n","\n","    def normalize(self):\n","        self.H.data = F.normalize(self.H.data, dim=0)\n","\n","    def forward(self, x):\n","\n","        # if testing use the H with the lowest err_H\n","        if self.eval_mode:\n","            H = self.bestH\n","        else:\n","            H = self.H\n","\n","        # for multiple phi use ith phi for image x\n","        if isinstance(x, tuple):\n","            i, x = x\n","            phiH = torch.matmul(self.phi[i], H)\n","            x = torch.matmul(self.phi[i], x)\n","        else:\n","            phiH = torch.matmul(self.phi, H)\n","            x = torch.matmul(self.phi, x)\n","\n","        num_batches = x.shape[0]\n","\n","        x_old = torch.zeros(num_batches, self.D_enc, 1, device=self.device)\n","        yk = torch.zeros(num_batches, self.D_enc, 1, device=self.device)\n","        x_new = torch.zeros(num_batches, self.D_enc, 1, device=self.device)\n","        t_old = torch.tensor(1, device=self.device).float()\n","\n","        phiH = phiH.to(self.device)\n","\n","        for t in range(self.T):\n","\n","            H_wt = x - torch.matmul(phiH, yk.view(-1, self.D_enc, 1))\n","            x_new = yk + torch.matmul(torch.t(phiH), H_wt) / self.L\n","            x_new = self.relu(torch.abs(x_new) - self.lam / self.L) * torch.sign(x_new)\n","\n","            t_new = (1 + torch.sqrt(1 + 4 * t_old * t_old)) / 2\n","            yk = x_new + (t_old - 1) / t_new * (x_new - x_old)\n","\n","            x_old = x_new\n","            t_old = t_new\n","\n","        return self.classifier(x_new.view(-1, self.D_enc))\n","\n","\n","class CRsAERandProjAeClassifier(torch.nn.Module):\n","    def __init__(self, hyp, H=None, phi=None):\n","        super(CRsAERandProjAeClassifier, self).__init__()\n","\n","        self.T = hyp[\"num_iters\"]\n","        self.L = hyp[\"L\"]\n","        self.lam = hyp[\"lam\"]\n","        self.D_in = hyp[\"D_in\"]\n","        self.D_org = hyp[\"D_org\"]\n","        self.D_enc = hyp[\"D_enc\"]\n","        self.device = hyp[\"device\"]\n","        self.eval_mode = False\n","\n","        if H is None:\n","            self.H = F.normalize(torch.randn(self.D_org, self.D_enc), dim=0)\n","        else:\n","            self.H = H\n","\n","        if phi is None:\n","            self.phi = F.normalize(torch.randn(1, self.D_in, self.D_org), dim=0)\n","        else:\n","            self.phi = phi\n","\n","        self.H = torch.nn.Parameter(self.H)\n","        self.phi = torch.nn.Parameter(self.phi)\n","        self.phi.requires_grad = False\n","\n","        self.H = self.H.to(self.device)\n","        self.phi = self.phi.to(self.device)\n","\n","        self.relu = torch.nn.ReLU()\n","        self.classifier = torch.nn.Linear(self.D_enc, 10)\n","        self.encoding_mode = False\n","\n","    def normalize(self):\n","        self.H.data = F.normalize(self.H.data, dim=0)\n","\n","    def forward(self, x):\n","        if self.encoding_mode:\n","            i, x = x\n","            return self.classifier(x.view(-1, self.D_enc))\n","\n","        # if testing use the H with the lowest err_H\n","        if self.eval_mode:\n","            H = self.bestH\n","        else:\n","            H = self.H\n","\n","        # for multiple phi use ith phi for image x\n","        if isinstance(x, tuple):\n","            i, x = x\n","            phiH = torch.matmul(self.phi[i], H)\n","            x = torch.matmul(self.phi[i], x)\n","        else:\n","            phiH = torch.matmul(self.phi, H)\n","            x = torch.matmul(self.phi, x)\n","\n","        num_batches = x.shape[0]\n","\n","        x_old = torch.zeros(num_batches, self.D_enc, 1, device=self.device)\n","        yk = torch.zeros(num_batches, self.D_enc, 1, device=self.device)\n","        x_new = torch.zeros(num_batches, self.D_enc, 1, device=self.device)\n","        t_old = torch.tensor(1, device=self.device).float()\n","\n","        phiH = phiH.to(self.device)\n","\n","        for t in range(self.T):\n","\n","            H_wt = x - torch.matmul(phiH, yk.view(-1, self.D_enc, 1))\n","            x_new = yk + torch.matmul(torch.t(phiH), H_wt) / self.L\n","            x_new = self.relu(torch.abs(x_new) - self.lam / self.L) * torch.sign(x_new)\n","\n","            t_new = (1 + torch.sqrt(1 + 4 * t_old * t_old)) / 2\n","            yk = x_new + (t_old - 1) / t_new * (x_new - x_old)\n","\n","            x_old = x_new\n","            t_old = t_new\n","\n","        z = torch.matmul(phiH, x_new)\n","        return (z, x_new, self.classifier(x_new.view(-1, self.D_enc)))"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0_Eo97KcPw9Q"},"source":["## Train"]},{"cell_type":"code","metadata":{"id":"amff0OW6ZByx","colab":{"base_uri":"https://localhost:8080/","height":229},"executionInfo":{"status":"error","timestamp":1626590655974,"user_tz":-330,"elapsed":363,"user":{"displayName":"NEIL PARESH MEHTA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsKd7M0H1Ghtta64n6eNaGRg03HOsuCRSk0KNj1A=s64","userId":"02534006225616056494"}},"outputId":"9a06d574-5ea6-458f-91f7-5a3c4efd9d97"},"source":["import torch\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import numpy as np\n","import pickle\n","import os\n","from datetime import datetime\n","from sacred import Experiment\n","\n","import sys\n","\n","sys.path.append(\"src/\")\n","\n","# import model, generator, trainer, utils, conf\n","\n","# from conf import config_ingredient\n","\n","import warnings\n","\n","warnings.filterwarnings(\"ignore\")\n","\n","ex = Experiment(\"train\", ingredients=[config_ingredient])\n","\n","\n","@ex.automain\n","def run(cfg):\n","\n","    hyp = cfg[\"hyp\"]\n","\n","    print(hyp)\n","\n","    random_date = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n","\n","    PATH = \"../results/{}/{}\".format(hyp[\"experiment_name\"], random_date)\n","    os.makedirs(PATH)\n","\n","    filename = os.path.join(PATH, \"hyp.pickle\")\n","    with open(filename, \"wb\") as file:\n","        pickle.dump(hyp, file)\n","\n","    print(\"load data.\")\n","    if hyp[\"dataset\"] == \"MNIST\":\n","        train_loader, test_loader = generator.get_MNIST_loaders(\n","            hyp[\"batch_size\"], shuffle=hyp[\"shuffle\"]\n","        )\n","        phis = F.normalize(\n","            torch.randn(hyp[\"num_phis\"], hyp[\"D_comp\"], hyp[\"D_org\"]), dim=1\n","        )\n","        H_init = None\n","    elif hyp[\"dataset\"] == \"simulated\":\n","        real_H, H_init, phis, train_loader = generator.generate_simulated_data(hyp)\n","    else:\n","        print(\"ERROR: dataset loader is not implemented.\")\n","\n","    print(\"create model.\")\n","    if hyp[\"network\"] == \"CRsAEDense\":\n","        net = model.CRsAEDense(hyp, H_init)\n","    elif hyp[\"network\"] == \"CRsAERandProj\":\n","        net = model.CRsAERandProj(hyp, H_init, phis)\n","    elif hyp[\"network\"] == \"CRsAERandProjClassifier\":\n","        net = model.CRsAERandProjClassifier(hyp, H_init, phis)\n","    elif hyp[\"network\"] == \"CRsAERandProjAeClassifier\":\n","        net = model.CRsAERandProjAeClassifier(hyp, H_init, phis)\n","    else:\n","        print(\"model does not exist!\")\n","\n","    torch.save(net.H, os.path.join(PATH, \"H_init.pt\"))\n","\n","    criterion = torch.nn.MSELoss()\n","    optimizer = optim.Adam(net.parameters(), lr=hyp[\"lr\"], eps=1e-3)\n","\n","    if hyp[\"classification\"]:\n","        net.H.requires_grad = True\n","        net.classifier.requires_grad = False\n","\n","    print(\"train auto-encoder.\")\n","    if hyp[\"dataset\"] == \"simulated\":\n","        if hyp[\"network\"] == \"CRsAEDense\":\n","            err = trainer.train_ae_simulated(\n","                net, train_loader, hyp, criterion, optimizer, real_H, PATH\n","            )\n","        elif hyp[\"network\"] == \"CRsAERandProj\":\n","            err = trainer.train_randproj_ae_simulated(\n","                net, train_loader, hyp, criterion, optimizer, real_H, phis, PATH\n","            )\n","\n","    else:\n","        err = trainer.train_ae(net, train_loader, hyp, criterion, optimizer, PATH)\n","\n","    if hyp[\"classification\"]:\n","        net.H.requires_grad = False\n","        net.classifier.requires_grad = True\n","\n","        optimizer.zero_grad()\n","        enc_tr_loader, enc_te_loader = generator.get_encoding_loaders(\n","            train_loader, test_loader, net, hyp\n","        )\n","\n","        criterion_class = torch.nn.CrossEntropyLoss()\n","\n","        print(\"train classifier.\")\n","        net.encoding_mode = True\n","        acc = trainer.train_classifier_encodings(\n","            net, enc_tr_loader, hyp, criterion_class, optimizer, enc_te_loader\n","        )\n","\n","        final_acc = (\n","            trainer.test_network(train_loader, net, hyp),\n","            trainer.test_network(test_loader, net, hyp),\n","        )\n","        net.encoding_mode = False\n","        print(\"final_acc\", final_acc)"],"execution_count":12,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-d3d6af9fb05b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mingredients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconfig_ingredient\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'config_ingredient' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"hdgq3ZTNPzgG"},"source":["## Trainer +Test"]},{"cell_type":"code","metadata":{"id":"_ZvOkleJP0qH","executionInfo":{"status":"ok","timestamp":1626590671189,"user_tz":-330,"elapsed":1008,"user":{"displayName":"NEIL PARESH MEHTA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsKd7M0H1Ghtta64n6eNaGRg03HOsuCRSk0KNj1A=s64","userId":"02534006225616056494"}}},"source":["import torch\n","import torch.nn.functional as F\n","from tqdm import tqdm\n","import os\n","\n","import sys\n","\n","sys.path.append(\"src/\")\n","\n","# import utils\n","\n","\n","\n","def train_ae_simulated(net, data_loader, hyp, criterion, optimizer, real_H, PATH):\n","\n","    num_epochs = hyp[\"num_epochs\"]\n","    device = hyp[\"device\"]\n","    info_period = hyp[\"info_period\"]\n","\n","    err = []\n","    for epoch in range(num_epochs):\n","        for idx, code in tqdm(enumerate(data_loader)):\n","\n","            img = torch.matmul(real_H, code.reshape(-1, net.D_enc, 1))\n","            img = img.to(device)\n","            # ===================forward=====================\n","            img_hat, _ = net(img)\n","            loss = criterion(img_hat, img)\n","            # ===================backward====================\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            net.normalize()\n","\n","            if idx % info_period == 0:\n","                print(\"loss:{:.4f}\".format(loss.item()))\n","\n","        err.append(utils.err_H(real_H, net.H.data))\n","        # ===================log========================\n","\n","        print(\n","            \"epoch [{}/{}], loss:{:.4f}, err_H:{:.4f}\".format(\n","                epoch + 1, num_epochs, loss.item(), err[-1]\n","            )\n","        )\n","\n","        torch.save(err[-1], os.path.join(PATH, \"err_epoch{}.pt\".format(epoch)))\n","\n","    return err\n","\n","\n","def train_randproj_ae_simulated(\n","    net, data_loader, hyp, criterion, optimizer, real_H, phi, PATH, test_loader=None\n","):\n","\n","    num_epochs = hyp[\"num_epochs\"]\n","    device = hyp[\"device\"]\n","    info_period = hyp[\"info_period\"]\n","\n","    err = []\n","    min_errH = 1\n","    bestH = None\n","    last_test_loss = 0\n","    true_decoder = torch.matmul(phi, real_H)\n","    true_decoder.requires_grad = False\n","\n","    # guarantee net() takes a tuple in forward pass\n","    if len(phi.size()) == 2:\n","        true_decoder = true_decoder.unsqueeze(0)\n","\n","    for epoch in range(num_epochs):\n","        for i, sample in tqdm(enumerate(data_loader)):\n","            # use ith phi to encode and decode\n","            i = i % true_decoder.size(0)\n","\n","            sample, true_decoder = sample.to(device), true_decoder.to(device)\n","\n","            img = torch.matmul(true_decoder[i], sample.view(-1, net.D_enc, 1)).view(\n","                -1, net.D_in, 1\n","            )\n","            # ===================forward=====================\n","            if len(phi.size()) == 2:\n","                img_hat, _ = net(img)\n","            else:\n","                img_hat, _ = net((i, img))\n","            loss = criterion(img_hat, img)\n","            # ===================backward====================\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            net.normalize()\n","\n","            if idx % info_period == 0:\n","                print(\"loss:{:.4f}\".format(loss.item()))\n","\n","        err.append(utils.err_H(real_H.cpu(), net.H.cpu().data))\n","\n","        if test_loader != None:\n","            for i, sample in tqdm(enumerate(test_loader)):\n","                # use ith phi to encode and decode\n","                i = i % true_decoder.size(0)\n","\n","                sample, true_decoder = sample.to(device), true_decoder.to(device)\n","\n","                img = torch.matmul(true_decoder[i], sample.view(-1, net.D_enc, 1)).view(\n","                    -1, net.D_in, 1\n","                )\n","                # ===================forward=====================\n","                if len(phi.size()) == 2:\n","                    img_hat, _ = net(img)\n","                else:\n","                    img_hat, _ = net((i, img))\n","                test_loss = criterion(img_hat, img)\n","\n","        # ===================log========================\n","        if err[-1] < min_errH:\n","            min_errH = err[-1]\n","            net.bestH = net.H.data\n","        if test_loader == None:\n","            print(\n","                \"epoch [{}/{}], loss:{:.4f}, err_H:{:.4f}\".format(\n","                    epoch + 1, num_epochs, loss.data, err[-1]\n","                )\n","            )\n","        else:\n","            print(\n","                \"epoch [{}/{}], loss:{:.4f}, test_loss:{:.4f}, err_H:{:.4f}\".format(\n","                    epoch + 1, num_epochs, loss.data, test_loss.data, err[-1]\n","                )\n","            )\n","\n","        if test_loader != None:\n","            if np.abs(test_loss.data - last_test_loss) < 5e-4:\n","                return err\n","            else:\n","                last_test_loss = test_loss.data\n","\n","        torch.save(err[-1], os.path.join(PATH, \"err_epoch{}.pt\".format(epoch)))\n","        torch.save(loss.item(), os.path.join(PATH, \"loss_epoch{}.pt\".format(epoch)))\n","\n","    return err\n","\n","\n","def train_ae(net, data_loader, hyp, criterion, optimizer, PATH):\n","\n","    num_epochs = hyp[\"num_epochs\"]\n","    device = hyp[\"device\"]\n","    info_period = hyp[\"info_period\"]\n","\n","    err = []\n","    min_err = None\n","    for epoch in range(num_epochs):\n","        for idx, (img, c) in tqdm(enumerate(data_loader)):\n","\n","            img = img.to(device)\n","            data = img.view(-1, net.D_org, 1)\n","\n","            if len(net.phi.size()) == 3:\n","                i = idx % net.phi.size(0)\n","\n","            # ===================forward=====================\n","            output = net((i, data))\n","            loss = criterion(output[0], torch.matmul(net.phi[i], data))\n","            # ===================backward====================\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            net.normalize()\n","\n","            if idx % info_period == 0:\n","                print(\"loss:{:.4f}\".format(loss.item()))\n","\n","        # ===================log========================\n","\n","        if min_err is None or min_err >= loss.data:\n","            min_err = loss.item()\n","            net.bestH = net.H.cpu().data\n","        err.append(loss.item())\n","        print(\"epoch [{}/{}], loss:{:.4f} \".format(epoch + 1, num_epochs, loss.item()))\n","\n","        torch.save(loss.item(), os.path.join(PATH, \"loss_epoch{}.pt\".format(epoch)))\n","\n","    return err\n","\n","\n","def train_classifier_encodings(\n","    net, data_loader, hyp, criterion, optimizer, val_loader=None, getHs=False\n","):\n","\n","    num_epochs = hyp[\"num_epochs\"]\n","    device = hyp[\"device\"]\n","    info_period = hyp[\"info_period\"]\n","\n","    train_acc = []\n","    val_acc = []\n","    Hs = []\n","    for epoch in tqdm(range(num_epochs)):\n","        for idx, (img, c) in enumerate(data_loader):\n","            img = img.to(device)\n","            c = c.to(device)\n","\n","            if len(net.phi.size()) == 3:\n","                i = idx % net.phi.size(0)\n","            # ===================forward=====================\n","\n","            output = net((i, img))\n","\n","            loss = criterion(output, c)\n","            # ===================backward====================\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            net.normalize()\n","\n","            if idx % info_period == 0:\n","                print(\"loss:{:.4f}\".format(loss.item()))\n","\n","        # ===================log========================\n","        train_acc.append(test_network(data_loader, net, hyp))\n","        val_acc.append(test_network(val_loader, net, hyp))\n","        Hs.append(net.H.cpu().data)\n","        print(\n","            \"epoch [{}/{}], loss:{:.4f}, train acc:{:.4f}, val acc:{:.4f}\".format(\n","                epoch + 1, num_epochs, loss.item(), train_acc[-1], val_acc[-1]\n","            )\n","        )\n","    if getHs:\n","        return train_acc, val_acc, Hs\n","    return train_acc, val_acc\n","\n","\n","def test_network(data_loader, net, hyp, getExamples=False, getClasses=False):\n","\n","    device = hyp[\"device\"]\n","\n","    with torch.no_grad():\n","        num_correct = 0\n","        num_total = 0\n","        correct_ex = []\n","        incorrect_ex = []\n","        examples = 300\n","        for idx, (img, c) in tqdm(enumerate(data_loader)):\n","\n","            img = img.to(device)\n","            c = c.to(device)\n","\n","            img = img.view(-1, net.D_enc, 1)\n","\n","            i = idx % net.phi.size(0)\n","            # ===================forward=====================\n","            output = net((i, img))\n","\n","            correct_indicators = output.max(1)[1].data == c\n","            num_correct += correct_indicators.sum().item()\n","            num_total += c.size()[0]\n","\n","            if getExamples:\n","                count = 0\n","                for j, indicator in enumerate(correct_indicators):\n","                    if indicator and len(correct_ex) <= examples:\n","                        correct_ex.append((i, img[j], c[j]))\n","                    elif not indicator and len(incorrect_ex) <= examples:\n","                        incorrect_ex.append((i, img[j], c[j]))\n","                    count += 1\n","                    if count > 4:\n","                        break\n","            if getClasses:\n","                correct\n","        # ===================log========================\n","\n","    acc = num_correct / num_total\n","    if getExamples:\n","        return (acc, correct_ex, incorrect_ex)\n","    return acc"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CB2c_s54S61k"},"source":["## Utils"]},{"cell_type":"code","metadata":{"id":"zoh-RbCKS9zF","executionInfo":{"status":"ok","timestamp":1626590673144,"user_tz":-330,"elapsed":357,"user":{"displayName":"NEIL PARESH MEHTA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsKd7M0H1Ghtta64n6eNaGRg03HOsuCRSk0KNj1A=s64","userId":"02534006225616056494"}}},"source":["import torch\n","import torch.nn.functional as F\n","import numpy as np\n","\n","\n","def normalize(x):\n","    x_normed = x / x.norm(dim=0, keepdim=True)\n","    return x_normed\n","\n","\n","def err_H(H, H_hat):\n","    err = 0\n","    for i in range(H.size()[1]):\n","        err_i = 1 - np.dot(H[:, i], H_hat[:, i]) ** 2\n","        if err_i > err:\n","            err = err_i\n","    return err\n","\n","\n","def err_H_min(H, H_hat):\n","    err = 1\n","    for i in range(H.size()[1]):\n","        err_i = 1 - np.dot(H[:, i], H_hat[:, i]) ** 2\n","        if err_i < err:\n","            err = err_i\n","    return err\n","\n","\n","def err_H_avg(H, H_hat):\n","    err = 0\n","    for i in range(H.size()[1]):\n","        err_i = 1 - np.dot(H[:, i], H_hat[:, i]) ** 2\n","        err += err_i\n","    return err / H.size()[1]\n","\n","\n","def err_H_all(H, H_hat):\n","    errs = []\n","    for i in range(H.size()[1]):\n","        err_i = 1 - np.dot(H[:, i], H_hat[:, i]) ** 2\n","        errs.append(err_i)\n","    return errs\n","\n","\n","def sample_var(dataset, real_H):\n","    return np.dot(dataset.samples.T, real_H.t()).var(1).mean()\n","\n","\n","def display_imgs(net, test_sparse, real_H, D_in):\n","    img = torch.matmul(test_sparse.view(1, -1), real_H.t()).view(-1, D_in, 1)\n","    plt.plot(img.flatten().data.numpy())\n","    comp_img = torch.matmul(net.phi.cpu().data, img)\n","    net(comp_img)\n","    plt.plot(torch.matmul(net.H.cpu(), net.last_encoding[0]).flatten().data.numpy())\n","    plt.legend([\"Real image\", \"Recovered image\"])\n","    plt.show()\n","\n","\n","def display_img_enc(net, real_H, dataset):\n","    i = 0\n","    net.eval_mode = True\n","    net.use_cuda = False\n","    recon_img = net(\n","        torch.matmul(torch.matmul(net.phi.cpu().data, real_H.cpu().data), dataset[i][0])\n","    ).view(1, -1)\n","    display_imgs(net, dataset[i][0], real_H.cpu(), net.D_org)\n","    plt.scatter(range(net.D_enc), dataset[i][0])\n","    plt.scatter(range(net.D_enc), net.last_encoding[0].cpu())\n","    plt.title(\"Learned H encodings lam = \" + str(net.lam))\n","    plt.legend([\"Real encoding\", \"Recovered encoding\"])\n","    plt.show()\n","\n","    net.use_cuda = True\n","\n","\n","def display_err_plot(errs, initial_err):\n","    plt.plot(range(len(errs) + 1), [initial_err] + list(errs))\n","    plt.title(\"Err vs Epoch\")\n","    plt.xlabel(\"Epoch\")\n","    plt.ylabel(\"Err\")\n","    plt.show()\n","\n","\n","def display_plots(net, real_H, dataset, errs, initial_err):\n","    display_img_enc(net, real_H, dataset)\n","    display_err_plot(errs, initial_err)\n","\n","\n","def save_model(net, acc, initial_H, name, num_iters, lam, mse):\n","    torch.save(\n","        net.H.data,\n","        name\n","        + \"_Din\"\n","        + str(net.D_in)\n","        + \"_Denc\"\n","        + str(net.D_enc)\n","        + \"_iters\"\n","        + str(num_iters)\n","        + \"_lam\"\n","        + str(lam)\n","        + \"H.pt\",\n","    )\n","    torch.save(\n","        net.classifier,\n","        name\n","        + \"_Din\"\n","        + str(net.D_in)\n","        + \"_Denc\"\n","        + str(net.D_enc)\n","        + \"_iters\"\n","        + str(num_iters)\n","        + \"_lam\"\n","        + str(lam)\n","        + \"classifier.pt\",\n","    )\n","    torch.save(\n","        torch.tensor(acc[0]),\n","        name\n","        + \"_Din\"\n","        + str(net.D_in)\n","        + \"_Denc\"\n","        + str(net.D_enc)\n","        + \"_iters\"\n","        + str(num_iters)\n","        + \"_lam\"\n","        + str(lam)\n","        + \"TrainAcc.pt\",\n","    )\n","    torch.save(\n","        torch.tensor(acc[1]),\n","        name\n","        + \"_Din\"\n","        + str(net.D_in)\n","        + \"_Denc\"\n","        + str(net.D_enc)\n","        + \"_iters\"\n","        + str(num_iters)\n","        + \"_lam\"\n","        + str(lam)\n","        + \"TestAcc.pt\",\n","    )\n","    torch.save(\n","        torch.tensor(mse),\n","        name\n","        + \"_Din\"\n","        + str(net.D_in)\n","        + \"_Denc\"\n","        + str(net.D_enc)\n","        + \"_iters\"\n","        + str(num_iters)\n","        + \"_lam\"\n","        + str(lam)\n","        + \"MSE.pt\",\n","    )\n","    torch.save(\n","        initial_H,\n","        name\n","        + \"_Din\"\n","        + str(net.D_in)\n","        + \"_Denc\"\n","        + str(net.D_enc)\n","        + \"_iters\"\n","        + str(num_iters)\n","        + \"_lam\"\n","        + str(lam)\n","        + \"initial_H.pt\",\n","    )"],"execution_count":14,"outputs":[]}]}